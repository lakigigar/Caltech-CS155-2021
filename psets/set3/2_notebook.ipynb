{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "2_notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakigigar/Caltech-CS155-2021/blob/main/psets/set3/2_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF1crkj-DTKO"
      },
      "source": [
        "# Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNkW8PGKDTKW"
      },
      "source": [
        "Import statements and function to load data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yXh6KLlUDTKX"
      },
      "source": [
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Seed the random number generator:\n",
        "np.random.seed(1)\n",
        "\n",
        "def load_data(filename, skiprows = 1):\n",
        "    \"\"\"\n",
        "    Function loads data stored in the file filename and returns it as a numpy ndarray.\n",
        "    \n",
        "    Inputs:\n",
        "        filename: given as a string.\n",
        "        \n",
        "    Outputs:\n",
        "        Data contained in the file, returned as a numpy ndarray\n",
        "    \"\"\"\n",
        "    return np.loadtxt(filename, skiprows=skiprows, delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLrmxR3hDTKa"
      },
      "source": [
        "Load the data and divide it into training and validation sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yli92gNpDTKb"
      },
      "source": [
        "# The number 24 in the next line corresponds to the number of header lines\n",
        "X = load_data('https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/psets/set3/data/messidor_features.arff',24)\n",
        "\n",
        "data = X[:, :-1]\n",
        "diag = X[:, -1]\n",
        "\n",
        "train_size = 900\n",
        "\n",
        "train_data = data[0:train_size]\n",
        "train_label = diag[0:train_size]\n",
        "test_data = data[train_size:]\n",
        "test_label = diag[train_size:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcZCTQQRDTKb"
      },
      "source": [
        "## Problem 2A(i): Decision Trees with Minimum Leaf Size Stopping Criterion\n",
        "\n",
        "There are two options, (i) and (ii) to choose from. If you do not plan to do the problem 2F, then delete or leave empty the cells for the other option.\n",
        "\n",
        "Fill in the two functions below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Kt1r-5y8DTKd"
      },
      "source": [
        "def classification_err(y, real_y):\n",
        "    \"\"\"\n",
        "    This function returns the classification error between two equally-sized vectors of \n",
        "    labels; this is the fraction of samples for which the labels differ.\n",
        "    \n",
        "    Inputs:\n",
        "        y: (N, ) shaped array of predicted labels\n",
        "        real_y: (N, ) shaped array of true labels\n",
        "    Output:\n",
        "        Scalar classification error\n",
        "    \"\"\"\n",
        "    #==============================================\n",
        "    # TODO: Implement the classification_err function,\n",
        "    # based on the above instructions.\n",
        "    #==============================================    \n",
        "    pass\n",
        "\n",
        "def eval_tree_based_model_min_samples(clf, min_samples_leaf, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    This function evaluates the given classifier (either a decision tree or random forest) at all of the \n",
        "    minimum leaf size parameters in the vector min_samples_leaf, using the given training and testing\n",
        "    data. It returns two vector, with the training and testing classification errors.\n",
        "    \n",
        "    Inputs:\n",
        "        clf: either a decision tree or random forest classifier object\n",
        "        min_samples_leaf: a (T, ) vector of all the min_samples_leaf stopping condition parameters \n",
        "                            to test, where T is the number of parameters to test\n",
        "        X_train: (N, D) matrix of training samples.\n",
        "        y_train: (N, ) vector of training labels.\n",
        "        X_test: (N, D) matrix of test samples\n",
        "        y_test: (N, ) vector of test labels\n",
        "    Output:\n",
        "        train_err: (T, ) vector of classification errors on the training data\n",
        "        test_err: (T, ) vector of classification errors on the test data\n",
        "    \"\"\"\n",
        "    #================================================================\n",
        "    # TODO: Implement the eval_tree_based_model_min_samples function,\n",
        "    # based on the above instructions.\n",
        "    #================================================================ \n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "H5eWpq1tDTKd"
      },
      "source": [
        "# Seed the random number generator:\n",
        "np.random.seed(1)\n",
        "\n",
        "min_samples_leaf = np.arange(1, 26)\n",
        "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
        "\n",
        "train_err, test_err = eval_tree_based_model_min_samples(clf, min_samples_leaf, train_data, \n",
        "                                                        train_label, test_data, test_label)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(min_samples_leaf, test_err, label='Testing error')\n",
        "plt.plot(min_samples_leaf, train_err, label='Training error')\n",
        "plt.xlabel('Minimum Node Size')\n",
        "plt.ylabel('Classification error')\n",
        "plt.title('Decision Tree with Gini Impurity and Minimum Node Size')\n",
        "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
        "plt.show()\n",
        "\n",
        "print('Test error minimized at min_samples_leaf = %i' % min_samples_leaf[np.argmin(test_err)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_t441edDTKe"
      },
      "source": [
        "## Problem 2A(ii): Decision Trees with Maximum Depth Stopping Criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3304HhiDTKg"
      },
      "source": [
        "Fill in the function below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fmdPE5zaDTKg"
      },
      "source": [
        "def eval_tree_based_model_max_depth(clf, max_depth, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    This function evaluates the given classifier (either a decision tree or random forest) at all of the \n",
        "    maximum tree depth parameters in the vector max_depth, using the given training and testing\n",
        "    data. It returns two vector, with the training and testing classification errors.\n",
        "    \n",
        "    Inputs:\n",
        "        clf: either a decision tree or random forest classifier object\n",
        "        max_depth: a (T, ) vector of all the max_depth stopping condition parameters \n",
        "                            to test, where T is the number of parameters to test\n",
        "        X_train: (N, D) matrix of training samples.\n",
        "        y_train: (N, ) vector of training labels.\n",
        "        X_test: (N, D) matrix of test samples\n",
        "        y_test: (N, ) vector of test labels\n",
        "    Output:\n",
        "        train_err: (T, ) vector of classification errors on the training data\n",
        "        test_err: (T, ) vector of classification errors on the test data\n",
        "    \"\"\"\n",
        "    #================================================================\n",
        "    # TODO: Implement the eval_tree_based_model_max_depth function,\n",
        "    # based on the above instructions.\n",
        "    #================================================================ \n",
        "    pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uVu4fiH5DTKi"
      },
      "source": [
        "# Seed the random number generator:\n",
        "np.random.seed(1)\n",
        "\n",
        "max_depth = np.arange(2, 21)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(criterion='gini')\n",
        "\n",
        "train_err, test_err = eval_tree_based_model_max_depth(clf, max_depth, train_data, \n",
        "                                                        train_label, test_data, test_label)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(max_depth, test_err, label='Testing error')\n",
        "plt.plot(max_depth, train_err, label='Training error')\n",
        "plt.xlabel('Maximum Tree Depth')\n",
        "plt.ylabel('Classification error')\n",
        "plt.title('Decision Tree with Gini Impurity and Maximum Tree Depth')\n",
        "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
        "plt.show()\n",
        "\n",
        "print('Test error minimized at max_depth = %i' % max_depth[np.argmin(test_err)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHw7Gq-EDTKj"
      },
      "source": [
        "## Problem 2C(i): Random Forests with Minimum Leaf Size Stopping Criterion\n",
        "\n",
        "There are two options, (i) and (ii) to choose from. If you do not plan to do the problems 2G, then leave empty or delete the cells for the other option."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "yIpZMC3kDTKj"
      },
      "source": [
        "# Seed the random number generator:\n",
        "np.random.seed(1)\n",
        "\n",
        "n_estimators = 1000\n",
        "clf = RandomForestClassifier(n_estimators = n_estimators, criterion = 'gini')\n",
        "\n",
        "min_samples_leaf = np.arange(1, 26)\n",
        "\n",
        "train_err, test_err = eval_tree_based_model_min_samples(clf, min_samples_leaf, train_data, \n",
        "                                                        train_label, test_data, test_label)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(min_samples_leaf, test_err, label='Testing error')\n",
        "plt.plot(min_samples_leaf, train_err, label='Training error')\n",
        "plt.xlabel('Minimum Node Size')\n",
        "plt.ylabel('Classification error')\n",
        "plt.title('Random Forest with Gini Impurity and Minimum Node Size')\n",
        "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
        "plt.show()\n",
        "\n",
        "print('Test error minimized at min_samples_leaf = %i' % min_samples_leaf[np.argmin(test_err)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q1SeXsZDTKj"
      },
      "source": [
        "## Problem 2C(ii): Random Forests with Maximum Depth Stopping Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "LdM7YnCZDTKj"
      },
      "source": [
        "# Seed the random number generator:\n",
        "np.random.seed(1)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = n_estimators, criterion = 'gini')\n",
        "\n",
        "max_depth = np.arange(2, 21)\n",
        "\n",
        "train_err, test_err = eval_tree_based_model_max_depth(clf, max_depth, train_data, \n",
        "                                                        train_label, test_data, test_label)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(max_depth, test_err, label='Testing error')\n",
        "plt.plot(max_depth, train_err, label='Training error')\n",
        "plt.xlabel('Maximum Depth')\n",
        "plt.ylabel('Classification error')\n",
        "plt.title('Random Forest with Gini Impurity and Maximum Depth')\n",
        "plt.legend(loc=0, shadow=True, fontsize='x-large')\n",
        "plt.show()\n",
        "\n",
        "print('Test error minimized at max_depth = %i' % max_depth[np.argmin(test_err)])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}