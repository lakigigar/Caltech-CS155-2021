{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [python3point5]",
      "language": "python",
      "name": "Python [python3point5]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "3_notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakigigar/CS155_Class_Materials/blob/master/2021/psets/set1/src/set1_prob3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT4wOGy9agAJ"
      },
      "source": [
        "# Problem 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FfOdVQKagAX"
      },
      "source": [
        "Use this notebook to write your code for problem 3 by filling in the sections marked `# TODO` and running all cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "343VuLgJagAY"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve('https://raw.githubusercontent.com/lakigigar/Caltech-CS155-2021/main/psets/set1/perceptron_helper.py', 'perceptron_helper.py')\n",
        "\n",
        "from perceptron_helper import (\n",
        "    predict,\n",
        "    plot_data,\n",
        "    boundary,\n",
        "    plot_perceptron,\n",
        ")\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaehsULoagAY"
      },
      "source": [
        "## Implementation of Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO_f8Z2QagAY"
      },
      "source": [
        "First, we will implement the perceptron algorithm. Fill in the `update_perceptron()` function so that it finds a single misclassified point and updates the weights and bias accordingly. If no point exists, the weights and bias should not change.\n",
        "\n",
        "Hint: You can use the `predict()` helper method, which labels a point 1 or -1 depending on the weights and bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Pr6wujMZagAZ"
      },
      "source": [
        "def update_perceptron(X, Y, w, b):\n",
        "    \"\"\"\n",
        "    This method updates a perceptron model. Takes in the previous weights\n",
        "    and returns weights after an update, which could be nothing.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing a single point.\n",
        "        Y: A (N, ) shaped numpy array containing the labels for the points.\n",
        "        w: A (D, ) shaped numpy array containing the weight vector.\n",
        "        b: A float containing the bias term.\n",
        "    \n",
        "    Output:\n",
        "        next_w: A (D, ) shaped numpy array containing the next weight vector\n",
        "                after updating on a single misclassified point, if one exists.\n",
        "        next_b: The next float bias term after updating on a single\n",
        "                misclassified point, if one exists.\n",
        "    \"\"\"\n",
        "    next_w, next_b = np.copy(w), np.copy(b)\n",
        "    \n",
        "    #==============================================\n",
        "    # TODO: Implement update rule for perceptron.\n",
        "    #===============================================\n",
        "    \n",
        "    return next_w, next_b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlA9xQtnagAZ"
      },
      "source": [
        "Next you will fill in the `run_perceptron()` method. The method performs single updates on a misclassified point until convergence, or max_iter updates are made. The function will return the final weights and bias. You should use the `update_perceptron()` method you implemented above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "cJhqDEzHagAZ"
      },
      "source": [
        "def run_perceptron(X, Y, w, b, max_iter):\n",
        "    \"\"\"\n",
        "    This method runs the perceptron learning algorithm. Takes in initial weights\n",
        "    and runs max_iter update iterations. Returns final weights and bias.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing a single point.\n",
        "        Y: A (N, ) shaped numpy array containing the labels for the points.\n",
        "        w: A (D, ) shaped numpy array containing the initial weight vector.\n",
        "        b: A float containing the initial bias term.\n",
        "        max_iter: An int for the maximum number of updates evaluated.\n",
        "        \n",
        "    Output:\n",
        "        w: A (D, ) shaped numpy array containing the final weight vector.\n",
        "        b: The final float bias term.\n",
        "    \"\"\"\n",
        "    \n",
        "    #============================================\n",
        "    # TODO: Implement perceptron update loop.\n",
        "    #=============================================\n",
        "\n",
        "    return w, b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DanB_eqUagAa"
      },
      "source": [
        "# Problem 3A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoPCcztlagAa"
      },
      "source": [
        "## Visualizing a Toy Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAl4zFe_agAa"
      },
      "source": [
        "We will begin by training our perceptron on a toy dataset of 3 points. The green points are labelled +1 and the red points are labelled -1. We use the helper function `plot_data()` to do so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tgkUZvoCagAa"
      },
      "source": [
        "X = np.array([[ -3, -1], [0, 3], [1, -2]])\n",
        "Y = np.array([ -1, 1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "dQBRNtVOagAb"
      },
      "source": [
        "fig = plt.figure(figsize=(5,4))\n",
        "ax = fig.gca(); ax.set_xlim(-4.1, 3.1); ax.set_ylim(-3.1, 4.1)\n",
        "plot_data(X, Y, ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwtprZ4tagAb"
      },
      "source": [
        "## Running the Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv7T_qPtagAb"
      },
      "source": [
        "Next, we will run the perceptron learning algorithm on this dataset. Update the code to show the weights and bias at each timestep and the misclassified point used in each update.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpA_Ig3lagAb"
      },
      "source": [
        "Run the below code, and fill in the corresponding table in the set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7uKUeY61agAb"
      },
      "source": [
        "# Initialize weights and bias.\n",
        "weights = np.array([0.0, 1.0])\n",
        "bias = 0.0\n",
        "\n",
        "weights, bias = run_perceptron(X, Y, weights, bias, 16)\n",
        "\n",
        "print()\n",
        "print (\"final w = %s, final b = %.1f\" % (weights, bias))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q9udTtTagAc"
      },
      "source": [
        "## Visualizating the Perceptron"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w17f89ckagAc"
      },
      "source": [
        "Getting all that information in table form isn't very informative. Let us visualize what the decision boundaries are at each timestep instead."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLeW17a7agAc"
      },
      "source": [
        "The helper functions `boundary()` and `plot_perceptron()` plot a decision boundary given a perceptron weights and bias. Note that the equation for the decision boundary is given by:\n",
        "\n",
        "$$w_1x_1 + w_2x_2 + b = 0.$$ \n",
        "\n",
        "Using some algebra, we can obtain $x_2$ from $x_1$ to plot the boundary as a line. \n",
        "\n",
        "$$x_2 = \\frac{-w_1x_2 - b}{w_2}. $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DNfp4YwagAd"
      },
      "source": [
        "Below is a redefinition of the `run_perceptron()` method to visualize the points and decision boundaries at each timestep instead of printing.  Fill in the method using your previous `run_perceptron()` method, and the above helper methods.\n",
        "\n",
        "Hint: The axs element is a list of Axes, which are used as subplots for each timestep. You can  do the following:\n",
        "```\n",
        "ax = axs[i]\n",
        "```\n",
        "to get the plot correponding to $t = i$. You can then use ax.set_title() to title each subplot. You will want to use the `plot_data()` and `plot_perceptron()` helper methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wazE5voTagAd"
      },
      "source": [
        "def run_perceptron(X, Y, w, b, axs, max_iter):\n",
        "    \"\"\"\n",
        "    This method runs the perceptron learning algorithm. Takes in initial weights\n",
        "    and runs max_iter update iterations. Returns final weights and bias.\n",
        "    \n",
        "    Inputs:\n",
        "        X: A (N, D) shaped numpy array containing a single point.\n",
        "        Y: A (N, ) shaped numpy array containing the labels for the points.\n",
        "        w: A (D, ) shaped numpy array containing the initial weight vector.\n",
        "        b: A float containing the initial bias term.\n",
        "        axs: A list of Axes that contain suplots for each timestep. \n",
        "        max_iter: An int for the maximum number of updates evaluated.\n",
        "        \n",
        "    Output:\n",
        "        The final weight and bias vectors.\n",
        "    \"\"\"\n",
        "    \n",
        "    #============================================\n",
        "    # TODO: Implement perceptron update loop.\n",
        "    #=============================================\n",
        "\n",
        "    return w, b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPvUxqLTagAd"
      },
      "source": [
        "Run the below code to get a visualization of the perceptron algorithm. The red region are areas the perceptron thinks are negative examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "2tGvBs_3agAe"
      },
      "source": [
        "# Initialize weights and bias.\n",
        "weights = np.array([0.0, 1.0])\n",
        "bias = 0.0\n",
        "\n",
        "f, ax_arr = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(9,8))\n",
        "axs = list(itertools.chain.from_iterable(ax_arr))\n",
        "for ax in axs:\n",
        "    ax.set_xlim(-4.1, 3.1); ax.set_ylim(-3.1, 4.1)\n",
        "\n",
        "run_perceptron(X, Y, weights, bias, axs, 4)\n",
        "\n",
        "f.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBQw_12OagAe"
      },
      "source": [
        "# Problem 3C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF_jD5z9agAe"
      },
      "source": [
        "## Visualize a Non-linearly Separable Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hKllA8lagAe"
      },
      "source": [
        "We will now work on a dataset that cannot be linearly separated, namely one that is generated by the XOR function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "KB0nlf6DagAf"
      },
      "source": [
        "X = np.array([[0, 1], [1, 0], [0, 0], [1, 1]])\n",
        "Y = np.array([1, 1, -1, -1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uvDQmz47agAf"
      },
      "source": [
        "fig = plt.figure(figsize=(5,4))\n",
        "ax = fig.gca(); ax.set_xlim(-0.1, 1.1); ax.set_ylim(-0.1, 1.1)\n",
        "plot_data(X, Y, ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNFppVfdagAf"
      },
      "source": [
        "We will now run the perceptron algorithm on this dataset. We will limit the total timesteps this time, but you should see a pattern in the updates. Run the below code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uF4bTSpbagAf"
      },
      "source": [
        "# Initialize weights and bias.\n",
        "weights = np.array([0.0, 1.0])\n",
        "bias = 0.0\n",
        "\n",
        "f, ax_arr = plt.subplots(4, 4, sharex=True, sharey=True, figsize=(9,8))\n",
        "axs = list(itertools.chain.from_iterable(ax_arr))\n",
        "for ax in axs:\n",
        "    ax.set_xlim(-0.1, 1.1); ax.set_ylim(-0.1, 1.1)\n",
        "    \n",
        "run_perceptron(X, Y, weights, bias, axs, 16)\n",
        "\n",
        "f.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}